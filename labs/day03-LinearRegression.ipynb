{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 135 day03: Linear Regression \n",
    "\n",
    "An investigation into the Formulas used for model training aka fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "* Learn how to apply the standard \"least squares\" formulas for 'training' linear regression in 1 dimension\n",
    "* Learn how to apply the standard \"least squares\" formulas for 'training' linear regression in many dimensions (with matrix math)\n",
    "* Learn how these formulas minimize *mean squared error*, but maybe not other error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Outline\n",
    "\n",
    "* [Part 1: Linear Regression with Linear Algebra](#Part-1:-Linear-Regression-with-Linear-Algebra)\n",
    "* [Part 2: What is a matrix inverse?](#Part-2:-What-is-the-inverse-of-a-matrix?)\n",
    "* [Part 3: When can we trust numerical computation of the inverse?](#Part-3:-Is-the-numerical-inverse-reliable?)\n",
    "* [Part 4: Returning to Linear Regression using numerically stable formulas](#Part-4:-Returning-to-general-case-linear-regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "* Exact formulas exist for estimating the weight coefficients $w$ and bias/intercept $b$ for linear regression\n",
    "* * When $F=1$, just involves ratios of inner products\n",
    "* * When $F>1$, requires matrix multiplication and other operations, solving a linear system with $F+1$ unknowns ($F$ weights and 1 bias)\n",
    "* Prefer `np.linalg.solve` over `np.linalg.inv`.\n",
    "* * Numerical methods for computing inverses (like `np.linalg.inv`) are unreliable if the matrix $A$ is almost singular.\n",
    "* Linear algebra is a very important field of mathematics for understanding when a solution to a linear system of equations exists\n",
    "* These formulas minimize *mean squared error*, but likely may not minimize other error metrics\n",
    "* * Many ML methods are motivated by what is *mathematically convenient*.\n",
    "* * In practice, you should *definitely* consider if another objective is better for your regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', style='whitegrid', font_scale=0.8)\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a simple 1D regression dataset\n",
    "\n",
    "* Use true slope of 2.345\n",
    "* Use true intercept of 0.0\n",
    "* Add a small amount of noise to each y value, so that the problem isn't \"too easy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_slope = 2.345\n",
    "\n",
    "N = 7\n",
    "x_N = np.linspace(-1, 1, N);\n",
    "ypure_N = true_slope * x_N\n",
    "\n",
    "prng = np.random.RandomState(987)\n",
    "y_N = ypure_N + 0.7 * prng.randn(N) # add Gaussian noise with stddev 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_N, ypure_N, 'bs-', label='y pure')\n",
    "plt.plot(x_N, y_N, 'rs-', label='y (noise added)');\n",
    "plt.legend(loc='lower right');\n",
    "plt.xlabel('x'); plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Linear Regression with 1 predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, all code is already written. Just read through it and make sure you understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction step\n",
    "\n",
    "Here, the prediction step for any specific scalar input $x$ is\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = w \\cdot x + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1d(x_N, w, b):\n",
    "    ''' Prediction step of F=1 linear regression with bias\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    yhat_N : 1D array, shape (N,)\n",
    "        Predicted y value for each entry in x_N\n",
    "    '''\n",
    "    N = np.asarray(x_N).shape\n",
    "    yhat_N = w * x_N + b # Elementwise multiply, then add\n",
    "    return yhat_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize MSE on training set, first compute the mean $x$ and the mean $y$:\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\text{mean}( y_1, \\ldots y_N)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\text{mean}( x_1, \\ldots x_N)\n",
    "$$\n",
    "\n",
    "\n",
    "Then, via formulas found in textbook, the best estimates of the slope and intercept (that minimize MSE) are given by:\n",
    "\n",
    "$$\n",
    "w^* = \\frac{ \\sum_{n=1}^N (x_n - \\bar{x}) (y_n - \\bar{y}) }{\\sum_{n=1}^N (x_n - \\bar{x})^2 }\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^* = \\bar{y} - w^* \\bar{x} \\quad \\quad \\quad \\quad\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the noise-free y value which actually do fall along a line\n",
    "\n",
    "Sanity check : we should recover the true-slope, with zero intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3449999999999998\n",
      "-1.7938032012157886e-16\n"
     ]
    }
   ],
   "source": [
    "xbar = np.mean(x_N)\n",
    "ybar = np.mean(ypure_N)\n",
    "w_est = np.inner(x_N - xbar, ypure_N - ybar) / np.inner(x_N - xbar, x_N - xbar)\n",
    "print(w_est)\n",
    "\n",
    "b_est = ybar - w_est * xbar\n",
    "print(b_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the noisy y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope: 2.8916527199994326\n",
      "Estimated bias: -0.17718525644944352\n"
     ]
    }
   ],
   "source": [
    "xbar = np.mean(x_N)\n",
    "ybar = np.mean(y_N)\n",
    "\n",
    "w_est = np.inner(x_N - xbar, y_N - ybar) / np.inner(x_N - xbar, x_N - xbar)\n",
    "b_est = ybar - w_est * xbar\n",
    "\n",
    "print(\"Estimated slope: \" + str(w_est))\n",
    "print(\"Estimated bias: \" + str(b_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear Regression with Linear Algebra\n",
    "\n",
    "Now we will do the same thing but with linear algebra. Because we still have only 1 predictor, we don't *have* to do linear algebra, and we could just apply the hand-derived equations. But we can apply the more general linear algebra approach to this setting and check that we get the same result.\n",
    "\n",
    "Given a dataset of $N$ examples and $F$ feature dimensions, where\n",
    "\n",
    "* $\\tilde{\\mathbf{X}}$ is an $N \\times F +1$ matrix of feature vectors, where we'll assume the last column is all ones\n",
    "* $\\mathbf{y}$ is an $N \\times 1$ column vector of outputs\n",
    "\n",
    "Goal:\n",
    "* estimate the vector $w \\in \\mathbb{R}^F$ of weight coefficients\n",
    "* estimate the bias scalar $b$ (aka intercept)\n",
    "\n",
    "Let's set $G = F +1$.\n",
    "\n",
    "Then, we can alternatively write our parameters as a compact vector of size $G$\n",
    "\n",
    "\\begin{align}\n",
    "\\theta &= [\\theta_1, \\theta_2, \\ldots \\theta_{F}, \\theta_{G}]\n",
    "\\\\\n",
    "    &= [ w_1, w_2, \\ldots w_F, b]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, lets first *form* the array $\\tilde{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_N1 = x_N[:,np.newaxis]\n",
    "x_N1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          1.        ]\n",
      " [-0.66666667  1.        ]\n",
      " [-0.33333333  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.33333333  1.        ]\n",
      " [ 0.66666667  1.        ]\n",
      " [ 1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "xtilde_N2 = np.hstack([x_N1, np.ones((x_N.size, 1))])\n",
    "print(xtilde_N2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code exercise: Prediction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xtilde_NG, theta_G):\n",
    "    ''' Prediction step of general linear regression\n",
    "    \n",
    "    G = number of features plus 1 (for intercept)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    yhat_N : 1D array, shape (N,)\n",
    "        Predicted y value for each entry in x_N\n",
    "    '''\n",
    "    assert isinstance(xtilde_NG, np.ndarray)\n",
    "    N, G = xtilde_NG.shape\n",
    "    assert theta_G.size == G\n",
    "    yhat_N = np.zeros(N) # TODO fixme\n",
    "    return yhat_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (A solution is provided at the end of the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Remember that the optimal vector $\\theta^*$ satisfies\n",
    "\n",
    "$$\n",
    "\\left( \\tilde{\\mathbf{X}}^T \\tilde{\\mathbf{X}} \\right) \\theta^* = \\tilde{\\mathbf{X}}^T \\mathbf{y}\n",
    "$$\n",
    "\n",
    "We can \"solve\" for theta by writing (**this critically assumes the inverse exists**)\n",
    "\n",
    "$$\n",
    "\\theta^* = (\\tilde{\\mathbf{X}}^T \\tilde{\\mathbf{X}} )^{-1} \\tilde{\\mathbf{X}}^T \\mathbf{y}\n",
    "\\\\\n",
    "~\\\\\n",
    "w^* = [\\theta^*_1 ~ \\theta^*_2 \\ldots \\theta^*_F ]^T\n",
    "\\\\\n",
    "~\\\\\n",
    "b^* = \\theta^*_{F+1}\n",
    "$$\n",
    "\n",
    "We need to compute a *matrix inverse* to do this (well, we don't actually *have to*, because there's only 1 feature. We could use the alternatively-derived solution in Part 0, but we won't).\n",
    "\n",
    "Let's try this out. First, print out the $\\tilde{X}$ array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  1.        ],\n",
       "       [-0.66666667,  1.        ],\n",
       "       [-0.33333333,  1.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.33333333,  1.        ],\n",
       "       [ 0.66666667,  1.        ],\n",
       "       [ 1.        ,  1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtilde_N2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets compute the matrix product $\\tilde{X}^T \\tilde{X}$, which is a $2 \\times 2$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.11111111e+00 -2.22044605e-16]\n",
      " [-2.22044605e-16  7.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "xTx_22 = np.matmul(xtilde_N2.T, xtilde_N2)\n",
    "print(xTx_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets compute the INVERSE of $\\tilde{X}^T \\tilde{X}$, which is again a $2 \\times 2$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.21428571e-01 1.01959257e-17]\n",
      " [1.01959257e-17 1.42857143e-01]]\n"
     ]
    }
   ],
   "source": [
    "inv_xTx_22 = np.linalg.inv(xTx_22) # compute the inverse!\n",
    "print(inv_xTx_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compute the optimal $\\theta$ vector according to our formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.89165272]\n",
      " [-0.17718526]]\n"
     ]
    }
   ],
   "source": [
    "theta_G = np.matmul(inv_xTx_22, np.matmul(xtilde_N2.T, y_N[:,np.newaxis])) # compute theta vector\n",
    "print(theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope: [2.89165272]\n",
      "Estimated bias: [-0.17718526]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated slope: \" + str(theta_G[0]))\n",
    "print(\"Estimated bias: \" + str(theta_G[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get the SAME results as in Part 0, from noisy data. \n",
    "\n",
    "So this formula for the general case looks super easy, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so fast...\n",
    "\n",
    "Let's take a minute and review just what the heck an *inverse* is, before we just blindly implement this formula..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: What is the inverse of a matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be a square matrix with shape $(D, D)$.\n",
    "\n",
    "We say that matrix $A^{-1}$ is the *inverse* of $A$ if the product of $A$ and $A^{-1}$ yields the $D \\times D$ *identity* matrix:\n",
    "\n",
    "$$\n",
    "A A^{-1} = I\n",
    "$$\n",
    "\n",
    "If $A^{-1}$ exists, it will also be a $D\\times D $ square matrix.\n",
    "\n",
    "In Python, we can compute the inverse of a matrix using `np.linalg.inv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0. -2.  0.]\n",
      " [ 0.  0.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# Define a square matrix with shape(3,3)\n",
    "A = np.diag(np.asarray([1., -2., 3.]))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.        ]\n",
      " [-0.         -0.5        -0.        ]\n",
      " [ 0.          0.          0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "# Compute its inverse\n",
    "invA = np.linalg.inv(A)\n",
    "print(invA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A, invA) # should equal identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, in 1 dimensions, the inverse of $a$ is just $1/a$, since $a \\cdot \\frac{1}{a} = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.asarray([[2]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]]\n"
     ]
    }
   ],
   "source": [
    "invA = np.linalg.inv(A)\n",
    "print(invA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the inverse always exist?\n",
    "\n",
    "No! Remember:\n",
    "\n",
    "* Even when $D=1$, if $A=0$, then the inverse does not exist ($\\frac{1}{A}$ is undefined)\n",
    "* When $D \\geq 2$, there are *infinitely many* square matrices $A$ that do not have an inverse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.   ]\n",
      " [0.    1.337]]\n",
      "<class 'numpy.linalg.LinAlgError'>: Singular matrix\n"
     ]
    }
   ],
   "source": [
    "# Example 1:\n",
    "A = np.asarray([[0, 0], [0, 1.337]])\n",
    "print(A)\n",
    "try:\n",
    "    np.linalg.inv(A)\n",
    "except Exception as e:\n",
    "    print(str(type(e)) + \": \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4 3.4]\n",
      " [3.4 3.4]]\n",
      "<class 'numpy.linalg.LinAlgError'>: Singular matrix\n"
     ]
    }
   ],
   "source": [
    "# Example 2:\n",
    "A = np.asarray([[3.4, 3.4], [3.4, 3.4]])\n",
    "print(A)\n",
    "try:\n",
    "    np.linalg.inv(A)\n",
    "except Exception as e:\n",
    "    print(str(type(e)) + \": \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2  4.7]\n",
      " [-2.4  9.4]]\n",
      "<class 'numpy.linalg.LinAlgError'>: Singular matrix\n"
     ]
    }
   ],
   "source": [
    "# Example 3:\n",
    "A = np.asarray([[-1.2, 4.7], [-2.4, 9.4]])\n",
    "print(A)\n",
    "try:\n",
    "    np.linalg.inv(A)\n",
    "except Exception as e:\n",
    "    print(str(type(e)) + \": \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these examples have in common???\n",
    "\n",
    "The columns of $A$ are not linearly independent!\n",
    "\n",
    "In other words, $A$ is not invertible whenever we can exactly construct one column of $A$ by a linear combination of other columns\n",
    "\n",
    "$$\n",
    "A_{:,D} = c_1 A_{:,1} + c_2 A_{:,2} + \\ldots c_{D-1} A_{:,D-1}\n",
    "$$\n",
    "\n",
    "where $c_1$, $c_2$, $\\ldots c_{D-1}$ are scalar weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2, -2.4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look, here's the first column:\n",
    "A[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2, -2.4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's it being perfectly reconstructed by a scalar times the second column\n",
    "A[:, 1] * -1.2/4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2. -3.]\n",
      " [ 2.  4. -6.]\n",
      " [ 1.  1.  1.]]\n",
      "<class 'numpy.linalg.LinAlgError'>: Singular matrix\n"
     ]
    }
   ],
   "source": [
    "# Example 3:\n",
    "A = np.asarray([[1.0, 2.0, -3.0], [2, 4, -6.0], [1.0, 1.0, 1.0]])\n",
    "print(A)\n",
    "try:\n",
    "    np.linalg.inv(A)\n",
    "except Exception as e:\n",
    "    print(str(type(e)) + \": \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important result from linear algebra: Invertible Matrix Theorem\n",
    "\n",
    "\n",
    "Given a specific matrix $A$, the following statements are either *all* true or *all* false:\n",
    "\n",
    "* $A$ has an inverse (e.g. a matrix $A^{-1}$ exists s.t. $A A^{-1} = I$)\n",
    "* All $D$ columns of $A$ are linearly independent\n",
    "* The columns of $A$ span the space $\\mathbb{R}^D$\n",
    "* $A$ has a non-zero determinant\n",
    "\n",
    "For more implications, see the *Invertible Matrix Theorem*:\n",
    "\n",
    "<https://en.wikipedia.org/wiki/Invertible_matrix#Properties>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Is the numerical inverse reliable?\n",
    "\n",
    "Can we always trust the results of `np.linalg.inv`?\n",
    "\n",
    "Not really. Taking inverses is very tricky if the input matrix is not *very* well conditioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A \"good\" example, where inverse works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 indep rows of size 3.\n",
    "prng = np.random.RandomState(8675309)\n",
    "\n",
    "x_NF = prng.randn(3, 3)\n",
    "xTx_FF = np.matmul(x_NF.T, x_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.89049845, -2.94940875,  0.53906734],\n",
       "       [-2.94940875,  1.95347099,  0.39420508],\n",
       "       [ 0.53906734,  0.39420508,  1.12274369]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(np.matmul(x_NF.T, x_NF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.89049845 -2.94940875  0.53906734]\n",
      " [-2.94940875  1.95347099  0.39420508]\n",
      " [ 0.53906734  0.39420508  1.12274369]]\n"
     ]
    }
   ],
   "source": [
    "# First, verify the `inv` function computes *something* of the right shape\n",
    "\n",
    "inv_xTx_FF = np.linalg.inv(xTx_FF)\n",
    "print(inv_xTx_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  3.78543709e-16 -1.02908588e-16]\n",
      " [ 1.00637374e-16  1.00000000e+00 -8.15941066e-17]\n",
      " [ 2.83970606e-16 -4.39010674e-16  1.00000000e+00]]\n",
      "\n",
      "is this close enough to identity matrix? True\n"
     ]
    }
   ],
   "source": [
    "# Next, verify the `inv` function result is ACTUALLY the inverse\n",
    "\n",
    "ans_FF = np.matmul(xTx_FF, inv_xTx_FF)\n",
    "\n",
    "print(ans_FF)\n",
    "print(\"\\nis this close enough to identity matrix? \" + str(\n",
    "    np.allclose(ans_FF, np.eye(3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A *bad* example, where `np.linalg.inv` may be unreliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 2 indep rows of size 3. should NOT be invertible                      \n",
    "# verify: determinant is close to zero                              \n",
    "x_NF = prng.randn(2, 3)  \n",
    "xTx_FF = np.matmul(x_NF.T, x_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72724601, -0.34643484, -0.61400395],\n",
       "       [-0.34643484,  0.80016893, -1.19669946],\n",
       "       [-0.61400395, -1.19669946,  4.01004776]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTx_FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.46265272e+15 2.94415957e+15 1.25568396e+15]\n",
      " [2.94415957e+15 3.51981240e+15 1.50119988e+15]\n",
      " [1.25568396e+15 1.50119988e+15 6.40261699e+14]]\n"
     ]
    }
   ],
   "source": [
    "# First, verify the `inv` function computes *something* of the right shape\n",
    "\n",
    "inv_xTx_FF = np.linalg.inv(xTx_FF)\n",
    "print(inv_xTx_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96261955  0.176167   -0.20301762]\n",
      " [ 0.06237689  0.34972495  0.106876  ]\n",
      " [-0.11882483  0.33249602  0.99899684]]\n",
      "\n",
      "is this close enough to identity matrix? False\n"
     ]
    }
   ],
   "source": [
    "# Next, verify the `inv` function result is ACTUALLY the inverse\n",
    "\n",
    "ans_FF = np.matmul(xTx_FF, inv_xTx_FF)\n",
    "\n",
    "print(ans_FF)\n",
    "print(\"\\nis this close enough to identity matrix? \" + str(\n",
    "    np.allclose(ans_FF, np.eye(3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "We just asked for an inverse.\n",
    "\n",
    "NumPy gave us a result that WAS NOT AN INVERSE, but we received NO WARNINGS OR ERRORS!\n",
    "\n",
    "So what should we do? Avoid naively calling `np.linalg.inv` and trusting the result. \n",
    "\n",
    "A better thing to do is use `np.linalg.solve`, as this will be more *stable* (trustworthy).\n",
    "\n",
    "<https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What `np.linalg.solve(A, b)` does is that it uses DIFFERENT algorithm to directly return an answer to the question\n",
    "\n",
    "What vector $\\theta$ would be a valid solution to the equation\n",
    "\n",
    "$$\n",
    "A \\theta = b\n",
    "$$\n",
    "\n",
    "for some matrix $A$ and vector $b$\n",
    "\n",
    "So for our case, we are requesting a solution (a specific vector $\\theta$) to the equation\n",
    "\n",
    "$$\n",
    "\\tilde{X}^T \\tilde{X} \\theta = \\tilde{X}^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Returning to general case linear regression\n",
    "\n",
    "Construct a simple case with $N=2$ examples and $F=2$ features.\n",
    "\n",
    "For general linear regression, this is an UNDER-determined system (we have 3 unknowns, but only 2 examples).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w_F1 = np.asarray([1.0, 1.0])[:,np.newaxis]\n",
    "true_b = np.asarray([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99912666 2.00015601]\n",
      " [0.9996129  0.99976079]]\n"
     ]
    }
   ],
   "source": [
    "x_NF = np.asarray([[1.0, 2.0], [1.0, 1.0]]) + prng.randn(2,2) * 0.001\n",
    "print(x_NF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.99928267]\n",
      " [1.99937369]]\n"
     ]
    }
   ],
   "source": [
    "y_N1 = np.matmul(x_NF, true_w_F1) + true_b\n",
    "print(y_N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick visual of what this dataset looks like. N=2, F=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axgrid = plt.subplots(nrows=1, ncols=2, figsize=(8,3));\n",
    "axgrid[0].plot(x_NF[:,0], y_N1, 'k.');\n",
    "axgrid[1].plot(x_NF[:,1], y_N1, 'k.');\n",
    "axgrid[0].set_ylabel('y')\n",
    "axgrid[0].set_xlabel('x1')\n",
    "axgrid[1].set_xlabel('x2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at what happens when we try to predict on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True y\n",
      "[2.99928267 1.99937369]\n",
      "Predictions with theta1: [ 7.24938235  1.00303752 -6.25      ]\n",
      "[0. 0.]\n",
      "Predictions with theta2: [1. 1. 0.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "theta1_G = np.asarray([7.24938235, 1.00303752, -6.25]);\n",
    "theta2_G = np.asarray([true_w_F1[0,0], true_w_F1[1,0], true_b[0]])\n",
    "xtilde_NG = np.hstack([x_NF, np.ones((2, 1))])\n",
    "\n",
    "print('True y')\n",
    "print(y_N1[:,0])\n",
    "print('Predictions with theta1: ' + str(theta1_G))\n",
    "print(predict(xtilde_NG, theta1_G)) # Assumes you have solved Exercise 3a\n",
    "print(\"Predictions with theta2: \" + str(theta2_G))\n",
    "print(predict(xtilde_NG, theta2_G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output of the above (if you've solved the coding exercise in Part 1)\n",
    "\n",
    "<pre>\n",
    "True y\n",
    "[2.99928267 1.99937369]\n",
    "Predictions with theta1: [ 7.24938235  1.00303752 -6.25      ]\n",
    "[2.99928267 1.99937369]\n",
    "Predictions with theta2: [1. 1. 0.]\n",
    "[2.99928267 1.99937369]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punchline: $N=F$, yet the model has $G = F+1$ free parameters. \n",
    "\n",
    "So, while not all parameters do well, there do exist INFINITELY many weights $w$ and bias values $b$ that can reconstruct our $y$ **perfectly**\n",
    "\n",
    "Question: Can various estimation strategies find such weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_NF, y_N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the estimated weights $w$ and intercept $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.85815419e-04  9.99513712e-01]]\n",
      "[1.0005847]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the predicted values for $y$, alongside the *true* ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for sklearn\n",
      "Predicted y: [2.99928267 1.99937369]\n",
      "True y:      [2.99928267 1.99937369]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for sklearn\")\n",
    "print(\"Predicted y: \" + str(np.squeeze(lr.predict(x_NF))))\n",
    "print(\"True y:      \" + str(np.squeeze(y_N1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for our formulas: make the $\\tilde{\\mathbf{X}}$ array\n",
    "\n",
    "Will have shape $N \\times (F+1)$\n",
    "\n",
    "Let's define $G = F+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99912666 2.00015601 1.        ]\n",
      " [0.9996129  0.99976079 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "xtilde_NG = np.hstack([x_NF, np.ones((2, 1))])\n",
    "print(xtilde_NG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTx_GG = np.matmul(xtilde_NG.T, xtilde_NG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out using our least-squares formula, as implemented with `np.linalg.inv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_xTx_GG = np.linalg.inv(xTx_GG)\n",
    "theta_G1 = np.matmul(inv_xTx_GG, np.matmul(xtilde_NG.T, y_N1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best estimate of the weights and bias (after \"unpacking\" the vector $\\theta$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.         1.00195312]\n",
      "[-4.]\n"
     ]
    }
   ],
   "source": [
    "w_F = theta_G1[:-1, 0]\n",
    "b = theta_G1[-1]\n",
    "print(w_F)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_N1 = np.matmul(xtilde_NG, theta_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for using naive np.linalg.inv\n",
      "Predicted y: [5.99707581 4.99861664]\n",
      "True y:      [2.99928267 1.99937369]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for using naive np.linalg.inv\")\n",
    "print(\"Predicted y: \" + str(yhat_N1[:,0]))\n",
    "print(\"True y:      \" + str(y_N1[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result: you should see that predictions might be *quite far* from true y values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out using our formulas, as implemented with `np.linalg.solve`\n",
    "\n",
    "What should happen: We can find estimated parameters $w, b$ that perfectly predict the $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_G1 = np.linalg.solve(xTx_GG, np.matmul(xtilde_NG.T, y_N1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.24938235 1.00303752]\n",
      "-6.25\n"
     ]
    }
   ],
   "source": [
    "w_F = theta_G1[:-1,0]\n",
    "b = theta_G1[-1,0]\n",
    "print(w_F)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_N1 = np.matmul(xtilde_NG, theta_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for using more stable formula implementation with np.linalg.solve\n",
      "Predicted y: [2.99928267 1.99937369]\n",
      "True y:      [2.99928267 1.99937369]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for using more stable formula implementation with np.linalg.solve\")\n",
    "print(\"Predicted y: \" + str(yhat_N1[:,0]))\n",
    "print(\"True y:      \" + str(y_N1[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION to Coding Exercise, Part 1\n",
    "\n",
    "```python\n",
    "def predict(xtilde_NG, theta_G):\n",
    "    ''' Prediction step of general linear regression\n",
    "    \n",
    "    G = number of features plus 1 (for intercept)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    yhat_N : 1D array, shape (N,)\n",
    "        Predicted y value for each entry in x_N\n",
    "    '''\n",
    "    N = np.asarray(x_N).shape\n",
    "    yhat_N = np.matmul(xtilde_NG, theta_G) # Matrix multiply \n",
    "    return yhat_N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
